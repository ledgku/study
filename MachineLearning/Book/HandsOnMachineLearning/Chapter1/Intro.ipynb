{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 1장 - 한눈에 보는 머신러닝\n",
    "\n",
    "### 머신러닝은 다음 분야에 뛰어나다.\n",
    "* 기존 솔루션으로는 많은 수동 조정과 규칙이 필요한 문제: 하나의 머신러닝 모델이 코드를 간단하게 만들고 전통적인 방법보다 더 잘 수행되도록 할 수 있다.\n",
    "* 전통적인 방식으로는 해결 방법이 없는 복잡한 문제: 가장 뛰어난 머신러닝 기법으로 해결 방법을 찾을 수 있다.\n",
    "* 유동적인 환경: 데이터에 변화가 발생 했을 때 자동적으로 이를 학습하고 적용한다.\n",
    "* 복잡한 문제와 대량의 데이터에서 패턴을 찾고 인사이트를 얻을 수 있음 (데이터 마이닝)\n",
    "\n",
    "### 머신러닝 시스템의 종류\n",
    "* 지도 학습 (supervised learning)\n",
    "    * 지도 학습에는 알고리즘에 주입하는 훈련 데이터에 레이블(label)이라는 원하는 답이 포함된다.\n",
    "    * 분류(classification)와 회귀(regression)가 대표적인 지도 학습 작업이다.\n",
    "    * 지도 학습 알고리즘에는 **k-nearest neighbors, linear/logistic regression, SVM, decision tree, random forest, neural networks** 등이 있다.\n",
    "    * <img alt=\"image\" src=\"https://user-images.githubusercontent.com/12126093/199903180-ca506728-52e5-4ef0-8078-991196024269.png\" width=\"600\"/>\n",
    "    * <img alt=\"image\" src=\"https://user-images.githubusercontent.com/12126093/199903223-236a72de-801b-441a-a9f6-63733fb39d85.png\" width=\"600\"/>\n",
    "\n",
    "* 비지도 학습 (unsupervised learning)\n",
    "    * 비지도 학습에는 훈련 데이터에 레이블이 없다. 시스템이 아무런 도움 없이 학습해야 한다.\n",
    "    * 비지도 학습 알고리즘에는 Clustering(k-means, DBSCAN, HCA, outlier/novelty detection), Visualization&Dimensionality reduction(PCA, LLE, t-SNE), Association rule learning(Apriori, Eclat) 등이 있다.\n",
    "    * <img alt=\"image\" src=\"https://user-images.githubusercontent.com/12126093/199903258-1f47b83f-7ab0-424b-a407-97ca944f42d0.png\" width=\"600\"/>\n",
    "    * <img alt=\"image\" src=\"https://user-images.githubusercontent.com/12126093/199903299-4105e3fd-19e6-4da9-b23c-4a4b564a6c34.png\" width=\"600\"/\n",
    "    * <img alt=\"image\" src=\"https://user-images.githubusercontent.com/12126093/199903386-8facd0ef-1e61-4941-b62d-9b5153289ee5.png\" width=\"600\"/>\n",
    "    * <img alt=\"image\" src=\"https://user-images.githubusercontent.com/12126093/199903426-d7390da3-3039-496f-b397-cdb229ec9091.png\" width=\"600\"/>\n",
    "\n",
    "* 준지도 학습 (semisupervised learning)\n",
    "    * 준지도 학습은 레이블이 일부만 있는 경우를 다룰 수 있다. (ex. 구글 포토)\n",
    "    * 준지도 학습은 지도 학습과 비지도 학습의 조합으로 이뤄져 있다.\n",
    "    * <img alt=\"image\" src=\"https://user-images.githubusercontent.com/12126093/199903458-9590cfc4-06b3-45e4-8ab8-47f7ea315b52.png\" width=\"600\"/>\n",
    "\n",
    "* 강화 학습 (reinforcement learning)\n",
    "    * 강화 학습에서 학습하는 시스템은 agent라고 하며 environment를 관찰해서 action을 하고 그 결과로 reward/penalty를 받는다.\n",
    "    * 시간이 지나면서 가장 큰 reward를 얻기 위해 policy라고 부르는 최상의 전략을 스스로 학습한다.\n",
    "\n",
    "* 배치 학습 (batch learning)\n",
    "    * 배치 학습에서는 시스템이 점진적으로 학습할 수 없고, 가용한 데이터를 모두 사용해 훈련시켜야 한다. (시간과 자원이 많이 소모되어 보통 오프라인에서 수행)\n",
    "    * 먼저 시스템을 훈련시키고 다음 제품 시스템에 적용하면 더 이상 학습 없이 실행된다.\n",
    "    * 새로운 데이터에 대해 학습하려면 전체 데이터로 새로운 버전을 처음부터 다시 훈련해야 한다.\n",
    "    * 훈련, 평가, 배포하는 과정을 자동화 해서 일정 주기로 업데이트 하도록 적용할 수 있다.\n",
    "    * 전체 데이터셋이 큰 경우 학습에 시간이 오래 걸리고 리소스도 많이 필요로 한다. 가용량을 넘어서면 학습이 불가능 할 수도 있다.\n",
    "\n",
    "* 온라인 학습 (online learning)\n",
    "    * 온라인 학습은 작은 단위의 데이터(mini batch)를 주입해 시스템을 훈련한다.\n",
    "    * 학습 단계가 빠르고 비용지 적게 들어 시스템은 데이터가 도착하는 대로 바로 학습할 수 있다. (주식처럼 빠른 변화에 스스로 적응해야 하는 시스템에 적합)\n",
    "    * 변화하는 데이터에 얼마나 빠르게 적응하는지를 나타내는 학습률(learning rate) 파라미터가 중요하다. (학습률이 높으면 최근 데이터에 민감하고 예전 데이터에는 둔감, 낮으면 최근 데이터에 둔감)\n",
    "    * 나쁜 데이터가 주입 됐을 때, 시스템 성능이 점진적으로 감소한다. (ex. 어뷰징)\n",
    "    * <img alt=\"image\" src=\"https://user-images.githubusercontent.com/12126093/199903534-deac0d20-fc5e-45a1-b28c-5a6cc2171487.png\" width=\"600\"/>\n",
    "    * <img alt=\"image\" src=\"https://user-images.githubusercontent.com/12126093/199903545-c72b4376-6ff4-4316-b26d-fb01a9bb591d.png\" width=\"600\"/>\n",
    "\n",
    "* 사례 기반 학습 (instance-based learning)\n",
    "    * 시스템이 훈련 샘플을 기억함으로써 학습한다. 유사도(similarity) 측정을 사용해 새로운 데이터와 학습한 샘플을 비교하는 식으로 일반화 한다.\n",
    "    * <img alt=\"image\" src=\"https://user-images.githubusercontent.com/12126093/199903576-b0bf6c57-802d-41dd-b19a-e3ddf4dc97f6.png\" width=\"600\"/>\n",
    "\n",
    "* 모델 기반 학습 (model-based learning)\n",
    "    * 샘플들의 모델을 만들어 예측(prediction)에 사용한다.\n",
    "    * 데이터를 보고 모델을 선택한다. 훈련 데이터로 모델을 훈련시켜 최적의 성능을 내도록 최적화 한다.\n",
    "    * 모델이 얼마나 좋은지 효용 함수(utility function) 또는 적합도 함수(finess funtion)을 정의하거나 얼마나 나쁜지 측정하는 비용 함수(cost function)를 정의해 사용한다.\n",
    "    * <img alt=\"image\" src=\"https://user-images.githubusercontent.com/12126093/199903594-546594a1-289d-48bc-b94c-1201c6b2c57f.png\" width=\"600\"/>\n",
    "\n",
    "### 머신러닝의 주요 도전 과제\n",
    "* 충분하지 않은 양의 훈련 데이터\n",
    "    * \"복잡한 문제에서 알고리즘보다 데이터가 더 중요하다.\"는 의견이 있다.\n",
    "    * 훈련 데이터를 모으는 일이 항상 쉽고 저렴한 일은 아니여서 아직은 알고리즘 개선에도 힘을 쏟아야 한다.\n",
    "* 대표성 없는 훈련 데이터\n",
    "    * 일반화 하기 원하는 새로운 사례를 훈련 데이터가 잘 대표하는 것이 중요하다.\n",
    "    * 샘플링 편향(sampling bias) 되지 않도록 대표성을 띄는 데이터를 사용하는게 중요하다. (샘플이 작으면 우연에 의한 대표성 없는 데이터들만 포함될 가능성이 크다.)\n",
    "* 낮은 품질의 데이터\n",
    "    * 데이터에 outlier, noise가 많으면 패턴을 찾기 어렵고 잘 작동하지 않는다. 따라서 데이터 정제에 많은 부분 시간을 사용해야 한다.\n",
    "    * outlier가 명확하면 제거하거나 값을 고치는게 좋다.\n",
    "    * 샘플에 일부 특성의 값이 빠져 있다면 해당 특성을 모두 제외할지, 이 샘플만 제외할지 빠진 값을 평균등으로 채울지 결정이 필요하다.\n",
    "* 관련 없는 특성\n",
    "    * 훈련에 사용할 좋은 특성을 찾는 feature engineering이 중요하다.\n",
    "    * feature selection: 가지고 있는 특성 중에서 훈련에 가장 유용한 특성을 선택한다.\n",
    "    * feature extraction: 특성을 결합해 더 유용한 특성을 만든다. (차원 축소 알고리즘이 도움이 될 수 있다.)\n",
    "* 훈련 데이터 과대적합 (overfitting)\n",
    "    * 훈련 데이터에 너무 잘 맞지만 일반성이 떨어지는 경우를 말한다.\n",
    "    * 국가별 삶의 만족도 모델에 나라 이름과 같은 관련 없는 특성을 추가하고 이름과 관련된 패턴을 우연히 찾았을 때, 해당 모델이 진짜인지 noise로 인한 것인지 모델이 구분할 수 없다.\n",
    "    * 과대적합은 훈련 데이터에 있는 noise 양에 비해 모델이 너무 복잡할 때 발생한다.\n",
    "        * 파라미터 수가 적은 모델을 선택하거나, 훈련 데이터에 있는 특성 수를 줄이거나 모델에 제약을 가해 단순화 시킨다.\n",
    "        * 훈련 데이터를 더 많이 모으로 noise를 줄인다.\n",
    "        * 모델을 단순하게 하고 overfitting의 위험을 감소시키기 위해 모델에 제약을 가하는 것을 규제(regularization)이라고 한다.\n",
    "        * 하이퍼파라미터(hyperparameter)를 증가시켜 제약을 증가시켜 모델을 단순하게 만든다.\n",
    "* 훈련 데이터 과소적합 (underfitting)\n",
    "    * 모델이 너무 단순해서 데이터의 내재된 구조를 학습하지 못할 때 발생한다.\n",
    "    * 해결을 위해서는 모델 파라미터가 더 많은 강력한 모델을 선택하거나, 더 좋은 특성을 제공한다. 또는 하이퍼파라미터를 감소시켜 모델의 제약을 줄인다.\n",
    "\n",
    "### 테스트와 검증\n",
    "* 학습이 완료된 모델은 평가하고 튜닝하는 과정이 필요하다.\n",
    "* 보통 훈련 데이터를 훈련 세트(80%)와 테스트 세트(20%) 두 개로 나눠서 사용한다. (데이터셋이 클 수록 테스트 세트의 비율은 줄어든다.)\n",
    "* 모델의 새로운 샘플에 대한 오류 비율을 일반화 오차(generalization error)라고 하며, 테스트 세트에서 모델을 평가해 이 오차에 대한 추정값을 얻는다. 즉, 새로운 샘플에 모델이 얼마나 잘 작동할지 알 수 있다.\n",
    "* 훈련 오차가 낮지만 일반화 오차가 크다면 모델이 훈련 데이터에 overfitting 되었다는 것을 의미한다.\n",
    "* 모델 평가는 각 모델을 같은 훈련 세트를 사용해 만든 다음 테스트 세트로 얼마나 일반화가 잘 되는지 비교해 선택한다.\n",
    "* 일반화 오차를 테스트 세트에서 여러번 측정하면 모델과 하이퍼파라미터가 테스트 세트에 최적화된 모델을 만들고 실제 데이터에서 성능이 예상만큼 좋지 않을 수 있는데, 일반적으로 홀드아웃 검증(holdout validation)과 K-fold 교차검증(K-fold cross validation)을 사용해 문제를 해결한다.\n",
    "* 조사를 통해 자신의 연구분야가 홀드아웃 검증과 K-fold 교차검증 중 어느 검증 방법을 채택하는지 살펴보고 사용하면 된다.\n",
    "* 홀드아웃 검증은 데이터셋을 훈련, 검증, 테스트 세트로 나누고, 훈련세트로는 모델을 훈련시키고 검증세트로는 모델의 최적 파라미터를 찾아 테스트세트로 모델의 성능을 평가한다. (테스트세트는 모델의 훈련과 성능 향상에 영향을 주지 않는다.)\n",
    "    * 검증 세트(validation set)는 개발 세트(development set) 또는 데브 세트(dev set)라고도 한다.\n",
    "    * 검증 세트가 너무 작으면 모델이 정확하게 평가되지 않고 너무 크면 훈련 세트가 작아지게 된다. 적당한 크기의 데이터세트에서 사용할 수 있으며 세트간 비율을 잘 설정해야 한다.\n",
    "* K-fold 교차검증은 데이터를 K개 서브셋으로 분리해 하나의 서브셋은 테스트에 나머지는 훈련에 사용하며 이를 K번 반복한다. K번 측정한 성능지표를 평균내 최종적으로 모델의 성능을 평가한다.\n",
    "    * 훈련 시간이 검증 세트의 개수에 비례해 늘어나는 단점이 있다.\n",
    "* 데이터 세트가 실제 제품에서 사용되는 데이터를 대표하지 못할 수 있다.\n",
    "    * 검증 세트와 테스트 세트에 실제 제품에서 기대하는 데이터를 베타적으로 반반 포함시켜야 한다.\n",
    "    * 검증 세트로 모델을 평가할 때 성능이 낮으면 \"훈련 세트에 과대적합 되었는지\" 또는 \"훈련 세트와 데이터가 불일치 하는지\" 두가지를 의심해 봐야 한다.\n",
    "    * 이럴 때에는 훈련 세트의 일부를 훈련-개발 세트로 떼어내고, 훈련 세트(훈련-개발 세트 데이터 제외)로 훈련 후 훈련-개발 세트에서 평가해야 한다. 훈련-개발 세트에서 성능이 좋았지만 검증 세트에서 나쁘면 데이터 불일치로 인한 것으로 훈련 세트의 데이터를 전처리 후 다시 훈련시켜야 한다. 훈련-개발 세트에서 성능이 좋지 못하면 훈련 세트에 과대 적합된 것이다.\n",
    "* 공짜 점심 없음 이론(no free lunch, NFL): 어떤 모델이 최선인지 확실히 아는 유일한 방법은 모든 모델을 평가해 보는 것 뿐이다.\n",
    "    * 실전에서는 데이터에 타당한 가정을 하고 적절한 모델 몇 가지만 평가한다.\n",
    "\n",
    "### 연습문제\n",
    "\n",
    "1. 머신러닝을 어떻게 정의할 수 있나요?\n",
    "알고리즘을 이용해 데이터를 분석하고 분석 결과를 스스로 학습한 후 이를 기반으로 어떠한 판단이나 예측을 하는 것\n",
    "\n",
    "2. 머신러닝이 동무을 줄 수 있는 문제 유형 네 가지를 말해보세요.\n",
    "사람이 만든 룰셋을 대체해야 하는 경우\n",
    "명확한 해결책이 없는 복잡한 문제\n",
    "계속해서 변화하는 환경에 적응해야 하는 시스템을 만드는 경우\n",
    "대량의 데이터에서 패턴을 찾아 인사이트를 발견해야 하는 문제\n",
    "\n",
    "3. 레이블된 훈련 세트란 무엇인가요?\n",
    "데이터에 사람이 생각하는 정답(label)이 달려있다.\n",
    "\n",
    "4. 가장 널리 사용되는 지도 학습 작업 두 가지는 무엇인가요?\n",
    "회귀, 분류\n",
    "\n",
    "5. 보편적인 비지도 학습 작업 네가지는 무엇인가요?\n",
    "클러스터링, 시각화, 차원축소, 연관 규칙 학습\n",
    "\n",
    "6. 사전 정보가 없는 여러 지형에서 로봇을 걸어가게 하려면 어떤 종류의 머신러닝 알고리즘을 사용할 수 있나요?\n",
    "강화 학습\n",
    "\n",
    "7. 고객을 여러 그룹으로 분할하려면 어떤 알고리즘을 사용해야 하나요?\n",
    "그룹에 대한 정보가 있다면 분류(지도학습), 없다면 클러스터링(비지도학습)을 사용할 수 있다.\n",
    "\n",
    "8. 스팸 감지의 문제는 지도 학습과 비지도 학습 중 어떤 문제로 볼 수 있나요?\n",
    "스팸 여부가 레이블이 돼 지도 학습에 해당한다.\n",
    "\n",
    "9. 온라인 학습 시스템이 무엇인가요?\n",
    "작은 단위의 데이터를 계속해서 학습하고 적용하는 시스템 (빠른 변화에 적응해야 하는 시스템에 적합)\n",
    "하이퍼파라미터에 따라 최신 데이터에 대한 민감도(학습률)를 조절할 수 있음\n",
    "\n",
    "10. 외부 메모리 학습이 무엇인가요?\n",
    "노드 한대의 메모리에 올릴 수 없는 큰 데이터셋을 학습할 때 주로 사용하며, 데이터를 작게 나누고 온라인 학습을 통해 학습한다.\n",
    "\n",
    "11. 예측을 하기 위해 유사도 측정에 의존하는 학습 알고리즘은 무엇인가요?\n",
    "사례 기반 학습, 유사도 측정을 통해 새로운 샘플이 가장 가까운 훈련 데이터 샘플을 찾고 예측에 사용함\n",
    "\n",
    "12. 모델 파라미터와 학습 알고리즘의 하이퍼파라미터 사이에는 어떤 차이가 있나요?\n",
    "사용자가 직접 설정하면 하이퍼 파라미터, 모델이나 데이터에 의해 결정되면 모델 파라미터이다.\n",
    "모델 파라미터는 모델 내부에서 데이터를 통해 결정된다. (ex. weight coefficient, bias)\n",
    "하이퍼 파라미터는 학습 알고리즘의 파라미터로 정해진 최적의 값은 없고 휴리스틱 또는 경험에 의해 결정하는 경우가 많다. (ex. learning rate, epoch, iteration)\n",
    "\n",
    "13. 모델 기반 알고리즘이 찾는 것은 무엇인가요? 성공을 위해 이 알고리즘이 사용하는 가장 일반적인 전략은 무엇인가요? 예측은 어떻게 만드나요?\n",
    "일반화 오류 값을 낮춰 좋은 성능을 내도록 모델 파라미터의 최적값을 찾는다.\n",
    "모델을 평가하는 함수(효용 또는 비용 함수)를 만들고 해당 함수에서 좋은 값을 받도록 학습시킨다.\n",
    "예측은 최적의 파라미터 값을 적용한 모델에 새로운 샘플 값을 주입시킨다.\n",
    "\n",
    "14. 머신러닝의 주요 도전 과제는 무엇인가요?\n",
    "부족한 데이터, 낮은 데이터 품질, 대표성 없는 데이터, 무의미한 특성, 훈련 데이터에 과소적합된 간단한 모델, 훈련 데이터에 과대적합된 복잡한 모델\n",
    "\n",
    "15. 모델이 훈련 데이터에서의 성능은 좋지만 새로운 샘플에서의 일반화 성능이 나쁘다면 어떤 문제가 있는 건가요? 가능한 해결책 세 가지는 무엇인가요?\n",
    "훈련데이터에 과대적합된 경우이다. 훈련 데이터에 더 많은 데이터를 추가하거나, 모델을 단순화(간단한 알고리즘으로 변경, 특성이나 파라미터 수 줄임, 규제 추가), 훈련 데이터에 노이즈를 제거한다.\n",
    "\n",
    "16. 테스트 세트가 무엇이고 왜 사용해야 하나요?\n",
    "모델의 일반화 오차를 추정하기 위해 사용한다.\n",
    "\n",
    "17. 검증 세트의 목적은 무엇인가요?\n",
    "테스트 세트를 통해 선택한 일반화가 잘 된 하나의 모델을 선택했을 때, 해당 모델의 하이퍼 파라미터 값을 선택하기 위해 사용한다.\n",
    "검증 세트에서 여러 하이퍼 파라미터를 가진 모델들의 성능을 측정하고 가장 높은 성능의 모델을 선택한다.\n",
    "\n",
    "18. 훈련-개발 세트가 무엇인가요? 언제 필요하고 어떻게 사용해야 하나요?\n",
    "훈련과 실제 서비스의 데이터가 다른 경우에 사용한다.\n",
    "훈련 세트의 일부를 훈련-개발 세트로 분리하고 모델의 과대적합, 데이터 불일치 여부를 판단할 때 사용한다.\n",
    "모델을 훈련 세트(훈련-개발 세트 데이터 제외)에서 훈련하고 훈련-개발 세트에서 평가 했을 때, 성능이 나쁘다면 훈련 세트에 과대 적합 된 것이다.\n",
    "훈련-개발 세트에서 성능이 좋은데 검증 세트에서 성능이 좋지 않다면 데이터 불일치가 있는 것으로 훈련 데이터가 실제 데이터와 가까워 지도록 개선이 필요하다.\n",
    "\n",
    "20. 테스트 세트를 사용해 하이퍼파라미터를 튜닝하면 어떤 문제가 생기나요?\n",
    "테스트 세트에 과대 적합될 수 있다. 성능 평가에서는 좋은 결과를 냈지만 실제 환경에서 안 좋은 성능을 나타낼 수 있다."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}